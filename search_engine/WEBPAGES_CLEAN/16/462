  Dr. Rina Dechter @ UCI  

 

     

 

   
   Course Reference 
   
   
    software 
  |  homeworks &amp; projects  |  handouts  
   
    
     
   
    
    Days: Tuesday /
       Thursday  
    Time: 2:00 p.m. - 3:20
       p.m.  
    Room: CS 219 
    Instructor: Rina Dechter 
    
   Course Description 
   
   
   One of the main challenges in building intelligent systems
  is the ability to reason under uncertainty, and one of the most successful
  approaches for dealing with this challenge is based on the framework of
  Bayesian belief networks. Intelligent systems based on Bayesian networks are
  currently being used in a number of real-world applications including
  diagnosis, sensor fusion, on-line help systems, credit assessment, and data
  mining.  
   The objective of this class is to provide an in-depth exposition of
  knowledge representation and reasoning under uncertainty using the framework
  of belief networks.  Both theoretical underpinnings and practical
  considerations will be covered, with a special emphasis on constructing
  graphical models and on exact and approximate inference algorithms.
  Additional topics include learning belief network parameters from Data,
  dynamic belief networks, reasoning about actions and planning under
  uncertainty. 
   
      
   
   Prerequisites 
   
    Familiarity with basic
       concepts of probability theory.  
    Knowledge of basic
       computer science, algorithms and programming principles.  
    Previous exposure to
       AI is desirable but not essential.  
      
   
   Tentative Syllabus 
   
       
     
       
     
     
      Topic  
     
     
      Date  
     
       Week 1   
     
    
     
      Introduction:
         Reasoning about beliefs using Logic and Probability (Pearl Chapters
         1-2) 
      
     
     10/1  
     
      
       
     
     
      Basic Bayes
         inference 
      
     
       
     
       Week 2   
     
    
     
      Bayesian network
         representation I:Independence Properties Syntax and Semantics (Pearl Chapter
         3) 
      
     
     10/8 
     
      
       
     
     
      Bayesian network
         representation II: Directed graphical models of independence 
      
     
       
     
       Week 3   
     
    
     
      Bayesian network
         representation III: Undirected graphical models of independence 
      
     
     10/15 
     
      
       
     
     
      Knowledge Engineering
         of Bayesian networks 
      
     
       
     
       Week 4   
     
    
     
      Exact inference
         using variable elimination methods 
      
     
     10/22 
     
      
       
     
     
      Complexity of
         inference tree-width 
      
     
       
     
       Week 5   
     
    
     
      Distributed
         inference I: Polytrees and jointrees (Pearl chapter 4) 
      
     
     10/29 
     
      
       
     
     
      Distributed
         inference II: Polytrees and jointrees 
      
     
       
     
       Week 6   
     
    
     
      Conditioning
         schemes Hybrids of inference and conditioning time-space tradeoffs 
      
     
     11/5 
     
      
       
     
     
      Canonical models
         &amp; local representation techniques 
      
     
       
     
       Week 7   
     
    
     
      Maximal a posteriori
         computations (MPE, MAP) and their applications (Pearl chapter )5 
      
     
     11/12 
     
      
       
     
     
      Approximate
         inference: Stochastistic methods Variables elimination methods
         Iterative belief propagation 
      
     
       
     
       Week 8   
     
    
     
      Learning Bayesian
         networks 
      
     
     11/19 
     
       Week 9   
     
    
     
      Decision and
         control I: Influence diagrams Maximizing expected utility Dynamic
         Bayesian networks (Pearl chapter 6) 
      
     
     11/26 
     
      
       
     
     
      Thanksgiving  
      
     
       
     
       Week 10   
     
    
     
      Assorted topics:
         Markov decision processes Inference: Policy iteration, value iteration
         Causality and action Students presentation 
      
     
     12/3 
     
         
   
   Readings (partial list) 
   
    Dechter, R.,   "Bucket
       Elimination: A unifying framework for Reasoning."    
    Judea Pearl,  Probabilistic
       Reasoning in Intelligent Systems.  Heckerman &amp; Breese,   Causal
       Independence for Probability Assessment and Inference Using Bayesian
       Networks .   
    Boutilier, Friedman,
       Goldszmidt &amp; Koller,   Context-Specific
       Independence in Bayesian Networks .   
    Dechter,   Bucket Elimination: A
       Unifying Framework for Probabilistic Inference .   
    Dechter,  "AAAI98
       tutorial on reasoning."   
    Heckerman,   A
       Tutorial on Learning with Bayesian Networks .   
    Kjaerulff,   dHugin:
       A Computational System for Dynamic Time-Sliced Bayesian Networks . 
        
    Pearl,   Causation,
       Action and Counterfactuals .   
    Dechter,    Mini-buckets:
       a general scheme for approximating inference.    
    Darwiche,   Recursive
       Conditioning: Any-space conditioning algorithm with treewidth-bounded
       complexity.    
    Darwiche,    Any-space
       probabilistic inference.    
    Darwiche,    On the role of
       partial differentiation in probabilistic inference.    
    Horvitz, Breese,
       Heckerman, Hovel &amp; Rommelse.   The Lumiere
       Project: Bayesian User Modeling for Inferring the Goals and Needs of
       Software Users.    
    Binder, Murphy,
       Russell.   Space-efficient
       inference in dynamic probabilistic networks.    
    Russell, Binder,
       Koller, Kanazawa.   Local
       learning in probabilistic networks with hidden variables.    
    Dugad &amp; Desai. 
        A Tutorial on
       Hidden Markov Models.    
    Friedman, Geiger,
       Goldszmidt.   Bayesian
       Network Classifiers.    
    Dechter, R., El
       Fattah, Y.,   Topological
       Parameters For Time-Space Tradeoff    
    Gagliardi, F.,   Generalizing
       Variable Elimination In Bayesian Networks    
    Rish, I; Dechter, R,
         AAAI
       2000 Tutorial    
      
   
   Books: 
   
    Judea Pearl. Probabilistic
       Reasoning in Intelligent Systems. Morgan Kaufmann, 1990.  
    Finn V. Jensen. An
       introduction to Bayesian networks. UCL Press, 1996.  
    Robert G. Cowell, A.
       Philip Dawid, Steffen L. Lauritzen, David J. Spiegelhalter Probabilistic
       Networks and Expert Systems Springer-Verlag, 1999  
    Castillo, E.;
       Gutierrez, J.M.; Hadi, A.S., Expert Systems and Probabilistic Network
       Models, Springer-Verlag 1997  
      
   
     Free Software 
   
    REES:   http://www.ics.uci.edu/~radum/rees.html 
        
    GeNIe/SMILE from the
       University of UPitt:   http://www2.sis.pitt.edu/~genie/ 
        
    Hugin lite from
       Hugin:   http://www.hugin.com   
    MSBN from Microsoft
       Research:  http://www.research.microsoft.com/dtas/msbn/ 
        
    JAVABayes from CMU:  http://www.cs.cmu.edu/~javabayes/Home/ 
        
    Netica from Norsys:  http://www.norsys.com   
      
   
   Related Links 
   
     A Brief
       Introduction to Graphical Models and Bayesian Networks   
     The Association for Uncertainty in Artificial
       Intelligence    Sponsors the conference on Uncertainty in
       Artificial Intelligence (UAI), which is the main yearly forum for
       reporting research results relating to Bayesian networks.   
     FreeBayesian
       Network Packages    A Brief
       Introduction to Graphical Models and Bayesian Networks   
     Artificial
       Intelligence: Probability studies may give computers a chance to learn ,
       by Kevin J. Delaney in Cambridge, England. The Wall Street Journal
       Europe.  
     AI on the web   
     UAI
       repository   
     More
       Inference Algorithms   
      
   
   Assignments: 
   
   There will be homework assignments and students will also
  be engaged in projects.  
   
   Grading Policy: 
   
   Homeworks and projects (50%),
  midterm (50%) 
   
    

     

  
 School of Information and Computer Science 
 University of California, Irvine, CA 92697-3435 
 Dr. Rina Dechter 

 dechter at ics.uci.edu 

   

</body> 